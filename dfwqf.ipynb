{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cuda')"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "import torchvision.transforms as transforms\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "\n",
    "class UECFoodPixDataset(Dataset):\n",
    "    def __init__(self, img_dir, mask_dir, file_list, transform=None, mask_transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.transform = transform\n",
    "        self.mask_transform = mask_transform\n",
    "\n",
    "        with open(file_list, 'r') as f:\n",
    "            self.image_ids = [line.strip() for line in f]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.img_dir, f\"{self.image_ids[idx]}.jpg\")\n",
    "        mask_name = os.path.join(self.mask_dir, f\"{self.image_ids[idx]}.png\")\n",
    "\n",
    "        image = Image.open(img_name).convert(\"RGB\")\n",
    "        mask = Image.open(mask_name).convert(\"RGB\")\n",
    "        mask = mask.split()[0]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        if self.mask_transform:\n",
    "            mask = self.mask_transform(mask)\n",
    "\n",
    "        return image, mask, self.image_ids[idx]\n",
    "\n",
    "# Data enhancement and preprocessing\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "\n",
    "mask_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.Lambda(lambda x: torch.from_numpy(np.array(x)).long())\n",
    "])\n",
    "\n",
    "# Train and test data dir\n",
    "train_img_dir = \"UECFOODPIXCOMPLETE/data/UECFoodPIXCOMPLETE/train/img\"\n",
    "train_mask_dir = \"UECFOODPIXCOMPLETE/data/UECFoodPIXCOMPLETE/train/mask\"\n",
    "test_img_dir = \"UECFOODPIXCOMPLETE/data/UECFoodPIXCOMPLETE/test/img\"\n",
    "test_mask_dir = \"UECFOODPIXCOMPLETE/data/UECFoodPIXCOMPLETE/test/mask\"\n",
    "category_file = \"UECFOODPIXCOMPLETE/data/category.txt\"\n",
    "train_list_file = \"UECFOODPIXCOMPLETE/data/train9000.txt\"\n",
    "test_list_file = \"UECFOODPIXCOMPLETE/data/test1000.txt\"\n",
    "\n",
    "train_dataset = UECFoodPixDataset(\n",
    "    img_dir=train_img_dir,\n",
    "    mask_dir=train_mask_dir,\n",
    "    file_list=train_list_file,\n",
    "    transform=train_transform,\n",
    "    mask_transform=mask_transform\n",
    ")\n",
    "num_classes = 103\n",
    "test_dataset = UECFoodPixDataset(\n",
    "    img_dir=test_img_dir,\n",
    "    mask_dir=test_mask_dir,\n",
    "    file_list=test_list_file,\n",
    "    transform=train_transform,\n",
    "    mask_transform=mask_transform\n",
    ")\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\课程\\9444\\Project\\j\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "D:\\课程\\9444\\Project\\j\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_BN_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_BN_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "\n",
    "import config\n",
    "from model_utils import *\n",
    "class SegNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SegNet, self).__init__()\n",
    "        self.vgg16_bn = models.vgg16_bn(pretrained=True).features\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.index_MaxPool = nn.MaxPool2d(kernel_size=2, stride=2, return_indices=True)\n",
    "        self.index_UnPool = nn.MaxUnpool2d(kernel_size=2, stride=2)\n",
    "        # net struct\n",
    "        self.conv1_block = nn.Sequential(\n",
    "            self.vgg16_bn[0],  # conv2d(3,64,(3,3))\n",
    "            self.vgg16_bn[1],  # bn(64,eps=1e-05,momentum=0.1,affine=True)\n",
    "            self.vgg16_bn[2],  # relu(in_place)\n",
    "            self.vgg16_bn[3],  # conv2d(3,64,(3,3))\n",
    "            self.vgg16_bn[4],  # bn(64,eps=1e-05,momentum=0.1,affine=True)\n",
    "            self.vgg16_bn[5],  # relu(in_place)\n",
    "        )\n",
    "        self.conv2_block = nn.Sequential(\n",
    "            self.vgg16_bn[7],\n",
    "            self.vgg16_bn[8],\n",
    "            self.vgg16_bn[9],\n",
    "            self.vgg16_bn[10],\n",
    "            self.vgg16_bn[11],\n",
    "            self.vgg16_bn[12],\n",
    "        )\n",
    "        self.conv3_block = nn.Sequential(\n",
    "            self.vgg16_bn[14],\n",
    "            self.vgg16_bn[15],\n",
    "            self.vgg16_bn[16],\n",
    "            self.vgg16_bn[17],\n",
    "            self.vgg16_bn[18],\n",
    "            self.vgg16_bn[19],\n",
    "            self.vgg16_bn[20],\n",
    "            self.vgg16_bn[21],\n",
    "            self.vgg16_bn[22],\n",
    "        )\n",
    "        self.conv4_block = nn.Sequential(\n",
    "            self.vgg16_bn[24],\n",
    "            self.vgg16_bn[25],\n",
    "            self.vgg16_bn[26],\n",
    "            self.vgg16_bn[27],\n",
    "            self.vgg16_bn[28],\n",
    "            self.vgg16_bn[29],\n",
    "            self.vgg16_bn[30],\n",
    "            self.vgg16_bn[31],\n",
    "            self.vgg16_bn[32],\n",
    "        )\n",
    "        self.conv5_block = nn.Sequential(\n",
    "            self.vgg16_bn[34],\n",
    "            self.vgg16_bn[35],\n",
    "            self.vgg16_bn[36],\n",
    "            self.vgg16_bn[37],\n",
    "            self.vgg16_bn[38],\n",
    "            self.vgg16_bn[39],\n",
    "            self.vgg16_bn[40],\n",
    "            self.vgg16_bn[41],\n",
    "            self.vgg16_bn[42],\n",
    "        )\n",
    "\n",
    "        self.upconv5_block = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=(3, 3), padding=(1, 1)),\n",
    "            nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True),\n",
    "            self.relu,\n",
    "            nn.Conv2d(512, 512, kernel_size=(3, 3), padding=(1, 1)),\n",
    "            nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True),\n",
    "            self.relu,\n",
    "            nn.Conv2d(512, 512, kernel_size=(3, 3), padding=(1, 1)),\n",
    "            nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True),\n",
    "            self.relu,\n",
    "        )\n",
    "        self.upconv4_block = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=(3, 3), padding=(1, 1)),\n",
    "            nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True),\n",
    "            self.relu,\n",
    "            nn.Conv2d(512, 512, kernel_size=(3, 3), padding=(1, 1)),\n",
    "            nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True),\n",
    "            self.relu,\n",
    "            nn.Conv2d(512, 256, kernel_size=(3, 3), padding=(1, 1)),\n",
    "            nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True),\n",
    "            self.relu,\n",
    "        )\n",
    "        self.upconv3_block = nn.Sequential(\n",
    "            nn.Conv2d(256, 256, kernel_size=(3, 3), padding=(1, 1)),\n",
    "            nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True),\n",
    "            self.relu,\n",
    "            nn.Conv2d(256, 256, kernel_size=(3, 3), padding=(1, 1)),\n",
    "            nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True),\n",
    "            self.relu,\n",
    "            nn.Conv2d(256, 128, kernel_size=(3, 3), padding=(1, 1)),\n",
    "            nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True),\n",
    "            self.relu,\n",
    "        )\n",
    "        self.upconv2_block = nn.Sequential(\n",
    "            nn.Conv2d(128, 128, kernel_size=(3, 3), padding=(1, 1)),\n",
    "            nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True),\n",
    "            self.relu,\n",
    "            nn.Conv2d(128, 64, kernel_size=(3, 3), padding=(1, 1)),\n",
    "            nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True),\n",
    "            self.relu,\n",
    "        )\n",
    "        self.upconv1_block = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, kernel_size=(3, 3), padding=(1, 1)),\n",
    "            nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True),\n",
    "            self.relu,\n",
    "            nn.Conv2d(64, 103, kernel_size=(3, 3), padding=(1, 1)),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        f1, idx1 = self.index_MaxPool(self.conv1_block(x))\n",
    "        f2, idx2 = self.index_MaxPool(self.conv2_block(f1))\n",
    "        f3, idx3 = self.index_MaxPool(self.conv3_block(f2))\n",
    "        f4, idx4 = self.index_MaxPool(self.conv4_block(f3))\n",
    "        f5, idx5 = self.index_MaxPool(self.conv5_block(f4))\n",
    "        up6 = self.index_UnPool(f5, idx5)\n",
    "        up5 = self.index_UnPool(self.upconv5_block(up6), idx4)\n",
    "        up4 = self.index_UnPool(self.upconv4_block(up5), idx3)\n",
    "        up3 = self.index_UnPool(self.upconv3_block(up4), idx2)\n",
    "        up2 = self.index_UnPool(self.upconv2_block(up3), idx1)\n",
    "        up1 = self.upconv1_block(up2)\n",
    "\n",
    "        return F.log_softmax(up1, dim=1)\n",
    "\n",
    "\n",
    "model = SegNet().to(device)\n",
    "lossf = nn.CrossEntropyLoss(ignore_index=255)\n",
    "optimizer = optim.Adam(model.parameters(),lr=0.0003)\n",
    "epochs_num = 10"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/282 [00:10<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 4.00 GiB of which 0 bytes is free. Of the allocated memory 3.42 GiB is allocated by PyTorch, and 56.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mOutOfMemoryError\u001B[0m                          Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[5], line 159\u001B[0m\n\u001B[0;32m    156\u001B[0m             plt\u001B[38;5;241m.\u001B[39mshow()\n\u001B[0;32m    157\u001B[0m             \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[1;32m--> 159\u001B[0m train_loss_history, train_acc_history, train_miou_history \u001B[38;5;241m=\u001B[39m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    160\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlossf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs_num\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_classes\u001B[49m\n\u001B[0;32m    161\u001B[0m \u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[5], line 54\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m(model, train_loader, test_loader, criterion, optimizer, device, epochs, num_classes)\u001B[0m\n\u001B[0;32m     52\u001B[0m \u001B[38;5;66;03m# 使用自动混合精度进行前向传播\u001B[39;00m\n\u001B[0;32m     53\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m autocast(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcuda\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m---> 54\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimages\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     55\u001B[0m     loss \u001B[38;5;241m=\u001B[39m criterion(outputs, masks)\n\u001B[0;32m     57\u001B[0m \u001B[38;5;66;03m# 混合精度反向传播和优化\u001B[39;00m\n",
      "File \u001B[1;32mD:\\课程\\9444\\Project\\j\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mD:\\课程\\9444\\Project\\j\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "Cell \u001B[1;32mIn[4], line 123\u001B[0m, in \u001B[0;36mSegNet.forward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m    121\u001B[0m up5 \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindex_UnPool(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mupconv5_block(up6), idx4)\n\u001B[0;32m    122\u001B[0m up4 \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindex_UnPool(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mupconv4_block(up5), idx3)\n\u001B[1;32m--> 123\u001B[0m up3 \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindex_UnPool(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mupconv3_block\u001B[49m\u001B[43m(\u001B[49m\u001B[43mup4\u001B[49m\u001B[43m)\u001B[49m, idx2)\n\u001B[0;32m    124\u001B[0m up2 \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindex_UnPool(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mupconv2_block(up3), idx1)\n\u001B[0;32m    125\u001B[0m up1 \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mupconv1_block(up2)\n",
      "File \u001B[1;32mD:\\课程\\9444\\Project\\j\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mD:\\课程\\9444\\Project\\j\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[1;32mD:\\课程\\9444\\Project\\j\\lib\\site-packages\\torch\\nn\\modules\\container.py:250\u001B[0m, in \u001B[0;36mSequential.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    248\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[0;32m    249\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[1;32m--> 250\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    251\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[1;32mD:\\课程\\9444\\Project\\j\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mD:\\课程\\9444\\Project\\j\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[1;32mD:\\课程\\9444\\Project\\j\\lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193\u001B[0m, in \u001B[0;36m_BatchNorm.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    186\u001B[0m     bn_training \u001B[38;5;241m=\u001B[39m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrunning_mean \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;129;01mand\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrunning_var \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m    188\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    189\u001B[0m \u001B[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001B[39;00m\n\u001B[0;32m    190\u001B[0m \u001B[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001B[39;00m\n\u001B[0;32m    191\u001B[0m \u001B[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001B[39;00m\n\u001B[0;32m    192\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m--> 193\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbatch_norm\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    194\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    195\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001B[39;49;00m\n\u001B[0;32m    196\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrunning_mean\u001B[49m\n\u001B[0;32m    197\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtraining\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrack_running_stats\u001B[49m\n\u001B[0;32m    198\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    199\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrunning_var\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtraining\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrack_running_stats\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    200\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    201\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    202\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbn_training\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    203\u001B[0m \u001B[43m    \u001B[49m\u001B[43mexponential_average_factor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    204\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43meps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    205\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\课程\\9444\\Project\\j\\lib\\site-packages\\torch\\nn\\functional.py:2812\u001B[0m, in \u001B[0;36mbatch_norm\u001B[1;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001B[0m\n\u001B[0;32m   2809\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m training:\n\u001B[0;32m   2810\u001B[0m     _verify_batch_size(\u001B[38;5;28minput\u001B[39m\u001B[38;5;241m.\u001B[39msize())\n\u001B[1;32m-> 2812\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbatch_norm\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   2813\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2814\u001B[0m \u001B[43m    \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2815\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2816\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrunning_mean\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2817\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrunning_var\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2818\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtraining\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2819\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmomentum\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2820\u001B[0m \u001B[43m    \u001B[49m\u001B[43meps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2821\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackends\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcudnn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43menabled\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2822\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mOutOfMemoryError\u001B[0m: CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 4.00 GiB of which 0 bytes is free. Of the allocated memory 3.42 GiB is allocated by PyTorch, and 56.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "from torch.amp import autocast, GradScaler\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "scaler = GradScaler()\n",
    "\n",
    "\n",
    "def calculate_iou(pred, mask, num_classes):\n",
    "    iou = []\n",
    "    pred = pred.cpu().numpy()\n",
    "    mask = mask.cpu().numpy()\n",
    "\n",
    "    # 计算所有类别的 IoU，包括背景类0\n",
    "    for cls in range(num_classes):\n",
    "        pred_cls = pred == cls\n",
    "        mask_cls = mask == cls\n",
    "        intersection = np.logical_and(pred_cls, mask_cls).sum()\n",
    "        union = np.logical_or(pred_cls, mask_cls).sum()\n",
    "        if union == 0:\n",
    "            iou.append(float('nan'))  # 避免分母为0时出错\n",
    "        else:\n",
    "            iou.append(intersection / union)\n",
    "\n",
    "    return np.nanmean(iou)  # 返回所有类的平均 IoU\n",
    "\n",
    "\n",
    "# 定义准确率计算函数，包括背景类0\n",
    "def calculate_accuracy(pred, mask):\n",
    "    pred = pred.cpu().numpy()\n",
    "    mask = mask.cpu().numpy()\n",
    "    correct = (pred == mask).sum()\n",
    "    total = mask.size\n",
    "    return correct / total\n",
    "\n",
    "\n",
    "# 训练函数\n",
    "def train(model, train_loader, test_loader, criterion, optimizer, device, epochs, num_classes):\n",
    "    model.train()\n",
    "    train_loss_history = []\n",
    "    train_acc_history = []\n",
    "    train_miou_history = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        running_acc = 0.0\n",
    "        running_miou = 0.0\n",
    "\n",
    "        for images, masks, _ in tqdm(train_loader):\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # 使用自动混合精度进行前向传播\n",
    "            with autocast(\"cuda\"):\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, masks)\n",
    "\n",
    "            # 混合精度反向传播和优化\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # 计算预测\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "\n",
    "            # 计算准确率和 IoU\n",
    "            running_acc += calculate_accuracy(preds, masks)\n",
    "            running_miou += calculate_iou(preds, masks, num_classes)\n",
    "\n",
    "            # 释放无用的变量，并清理显存\n",
    "            del outputs, loss, preds\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        # 计算每个 epoch 的平均 loss、accuracy 和 mIoU\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        epoch_acc = running_acc / len(train_loader)\n",
    "        epoch_miou = running_miou / len(train_loader)\n",
    "\n",
    "        train_loss_history.append(epoch_loss)\n",
    "        train_acc_history.append(epoch_acc)\n",
    "        train_miou_history.append(epoch_miou)\n",
    "\n",
    "        print(\n",
    "            f\"Epoch [{epoch + 1}/{epochs}], Train Loss: {epoch_loss:.4f}, Train Accuracy: {epoch_acc:.4f}, Train mIoU: {epoch_miou:.4f}\")\n",
    "\n",
    "        # 在每个 epoch 后保存模型\n",
    "        torch.save(model.state_dict(), f\"segnet_epoch_{epoch + 1}.pth\")\n",
    "\n",
    "        # 在测试集上运行评估\n",
    "        #test_acc, test_miou = evaluate_model(model, test_loader, device, num_classes)\n",
    "       # test_acc_history.append(test_acc)\n",
    "        #test_miou_history.append(test_miou)\n",
    "      #  print(f\"Epoch [{epoch + 1}/{epochs}], Test Accuracy: {test_acc:.4f}, Test mIoU: {test_miou:.4f}\")\n",
    "        visualize_predictions(model, test_loader, device, num_samples=4)\n",
    "    return train_loss_history, train_acc_history, train_miou_history\n",
    "\n",
    "\n",
    "# 测试集上的评估函数\n",
    "def evaluate_model(model, test_loader, device, num_classes):\n",
    "    model.eval()\n",
    "    total_acc = 0.0\n",
    "    total_miou = 0.0\n",
    "    num_batches = len(test_loader)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, masks, _ in test_loader:\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "\n",
    "            # 计算准确率和 IoU\n",
    "            total_acc += calculate_accuracy(preds, masks)\n",
    "            total_miou += calculate_iou(preds, masks, num_classes)\n",
    "\n",
    "    avg_acc = total_acc / num_batches\n",
    "    avg_miou = total_miou / num_batches\n",
    "\n",
    "    return avg_acc, avg_miou\n",
    "\n",
    "\n",
    "def visualize_predictions(model, test_loader, device, num_samples=4):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, masks, ids in test_loader:\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "\n",
    "            print(\"Preds:\", preds[0].cpu().numpy())  # 打印第一个样本的预测\n",
    "            unique_values = torch.unique(preds).cpu().numpy()\n",
    "            print(\"Unique predicted classes:\", unique_values)  # 打印预测中包含的唯一类别\n",
    "\n",
    "            # 随机选择num_samples个索引\n",
    "            indices = random.sample(range(len(images)), min(num_samples, len(images)))\n",
    "\n",
    "            fig, axes = plt.subplots(3, num_samples, figsize=(15, 8))\n",
    "            for i, idx in enumerate(indices):\n",
    "                # 显示原始图像\n",
    "                axes[0, i].imshow(images[idx].cpu().permute(1, 2, 0))\n",
    "                axes[0, i].set_title(f\"Test Image ID: {ids[idx]}\")\n",
    "                axes[0, i].axis('off')\n",
    "\n",
    "                # 显示真实掩码\n",
    "                axes[1, i].imshow(masks[idx].cpu())\n",
    "                axes[1, i].set_title(\"Ground Truth\")\n",
    "                axes[1, i].axis('off')\n",
    "\n",
    "                # 显示模型预测掩码\n",
    "                axes[2, i].imshow(preds[idx].cpu())\n",
    "                axes[2, i].set_title(\"Predicted Mask\")\n",
    "                axes[2, i].axis('off')\n",
    "\n",
    "            plt.show()\n",
    "            break\n",
    "\n",
    "train_loss_history, train_acc_history, train_miou_history = train(\n",
    "    model, train_loader, test_loader, lossf, optimizer, device, epochs_num, num_classes\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
